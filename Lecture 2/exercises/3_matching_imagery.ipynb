{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3 - Matching Imagery\n",
    "---\n",
    "\n",
    "<a style=\"display: inline-block;\" href=\"https://mybinder.org/v2/gh/RadiantMLHub/ml4eo-bootcamp-2021/main?filepath=Lecture%202%2Fexercises%2F3_matching_imagery.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Launch in Binder\"/></a>\n",
    "\n",
    "For this exercise we will match our input data with Sentinel-2 Imagery which matches the spatial and temporal extent of the input data. We will use the same temporal range that we explored in the first exercise but you can modify this value to be whatever you like. We can see with this next cell that our input data all falls within one Sentinel-2 tile (34HCH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape, GeometryCollection, box\n",
    "import arrow\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import os\n",
    "\n",
    "\n",
    "with fiona.open('../data/south_africa_crops/south_africa_crops.shp') as input_data:\n",
    "    crop_collection = GeometryCollection([ shape(crop['geometry']).buffer(0) for crop in input_data ])    \n",
    "    b = crop_collection.bounds\n",
    "    crop_collection = box(b[0], b[1], b[2], b[3])\n",
    "    \n",
    "date_range = [arrow.get('2017-05-15', 'YYYY-MM-DD'), arrow.get('2018-03-10', 'YYYY-MM-DD')]\n",
    "tiles = []\n",
    "\n",
    "with fiona.open('../data/sentinel_2_tiles.geojson') as sentinel_2_tiles:\n",
    "    for tile in sentinel_2_tiles:\n",
    "        tile_name = tile['properties']['Name']\n",
    "        tile_shape = shape(tile['geometry'])\n",
    "        \n",
    "        if tile_shape.intersects(crop_collection):\n",
    "            tiles.append(tile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34HCH']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for Imagery\n",
    "---\n",
    "\n",
    "These next few cells will find all of the Sentinel-2 scenes which fall within our temporal and spatial ranges. We see here that there are 58 scenes which match our requirements. The S3 bucket which we are grabbing our imagery from does not require authentication but other buckets, such as the official [Sentinel-2 bucket](https://registry.opendata.aws/sentinel-2/) require authentication and are requestor pays, meaning you will be billed for the data transfer costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "def get_matching_s3_keys(bucket, prefix='', suffix=''):\n",
    "    kwargs = {'Bucket': bucket, 'Prefix': prefix}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp['Contents']:\n",
    "            key = obj['Key']\n",
    "            if key.endswith(suffix):\n",
    "                yield key\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_scenes = []\n",
    "\n",
    "for tile in tiles:\n",
    "    keys = list(get_matching_s3_keys('sentinel-cogs', prefix=f'sentinel-s2-l2a-cogs/{tile[0:2]}/{tile[2]}/{tile[3:5]}/'))\n",
    "    for key in keys:\n",
    "        scene_id = key.split('/')[-2]\n",
    "        scene_date = arrow.get(scene_id.split('_')[2], 'YYYYMMDD')\n",
    "        if scene_id not in matching_scenes and scene_date >= date_range[0] and scene_date <= date_range[1]:\n",
    "            matching_scenes.append(scene_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 matching scenes\n",
      "['S2A_34HCH_20171008_0_L2A', 'S2A_34HCH_20171018_0_L2A', 'S2A_34HCH_20171028_0_L2A', 'S2B_34HCH_20171003_0_L2A', 'S2B_34HCH_20171013_0_L2A', 'S2B_34HCH_20171023_0_L2A', 'S2A_34HCH_20171107_0_L2A', 'S2A_34HCH_20171117_0_L2A', 'S2A_34HCH_20171127_0_L2A', 'S2A_34HCH_20171127_1_L2A', 'S2B_34HCH_20171102_0_L2A', 'S2B_34HCH_20171112_0_L2A', 'S2B_34HCH_20171112_1_L2A', 'S2B_34HCH_20171112_2_L2A', 'S2B_34HCH_20171122_0_L2A', 'S2A_34HCH_20171207_0_L2A', 'S2A_34HCH_20171217_0_L2A', 'S2A_34HCH_20171227_0_L2A', 'S2B_34HCH_20171202_0_L2A', 'S2B_34HCH_20171212_0_L2A', 'S2B_34HCH_20171222_0_L2A', 'S2A_34HCH_20170521_0_L2A', 'S2A_34HCH_20170531_0_L2A', 'S2A_34HCH_20170610_0_L2A', 'S2A_34HCH_20170610_1_L2A', 'S2A_34HCH_20170620_0_L2A', 'S2A_34HCH_20170630_0_L2A', 'S2A_34HCH_20170710_0_L2A', 'S2A_34HCH_20170720_0_L2A', 'S2A_34HCH_20170730_0_L2A', 'S2B_34HCH_20170705_0_L2A', 'S2B_34HCH_20170705_1_L2A', 'S2B_34HCH_20170715_0_L2A', 'S2B_34HCH_20170715_1_L2A', 'S2B_34HCH_20170725_0_L2A', 'S2A_34HCH_20170809_0_L2A', 'S2A_34HCH_20170819_0_L2A', 'S2A_34HCH_20170829_0_L2A', 'S2B_34HCH_20170804_0_L2A', 'S2B_34HCH_20170814_0_L2A', 'S2B_34HCH_20170824_0_L2A', 'S2A_34HCH_20170908_0_L2A', 'S2A_34HCH_20170918_0_L2A', 'S2A_34HCH_20170928_0_L2A', 'S2B_34HCH_20170923_0_L2A', 'S2A_34HCH_20180106_0_L2A', 'S2A_34HCH_20180116_0_L2A', 'S2A_34HCH_20180126_0_L2A', 'S2B_34HCH_20180101_0_L2A', 'S2B_34HCH_20180111_0_L2A', 'S2B_34HCH_20180121_0_L2A', 'S2B_34HCH_20180131_0_L2A', 'S2A_34HCH_20180215_0_L2A', 'S2A_34HCH_20180225_0_L2A', 'S2B_34HCH_20180210_0_L2A', 'S2B_34HCH_20180220_0_L2A', 'S2A_34HCH_20180307_0_L2A', 'S2B_34HCH_20180302_0_L2A']\n"
     ]
    }
   ],
   "source": [
    "print(f'Found {len(matching_scenes)} matching scenes')\n",
    "print(matching_scenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing Available Assets\n",
    "---\n",
    "\n",
    "The code below will list the assets available for download in the first scene. Here, we can see that there's a True Color composite image (TCI.tif) available and we will be downloading that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"AOT.tif\",\n",
      "    \"B01.tif\",\n",
      "    \"B02.tif\",\n",
      "    \"B03.tif\",\n",
      "    \"B04.tif\",\n",
      "    \"B05.tif\",\n",
      "    \"B06.tif\",\n",
      "    \"B07.tif\",\n",
      "    \"B08.tif\",\n",
      "    \"B09.tif\",\n",
      "    \"B11.tif\",\n",
      "    \"B12.tif\",\n",
      "    \"B8A.tif\",\n",
      "    \"L2A_PVI.tif\",\n",
      "    \"S2A_34HCH_20171008_0_L2A.json\",\n",
      "    \"SCL.tif\",\n",
      "    \"TCI.tif\",\n",
      "    \"WVP.tif\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for scene in matching_scenes:\n",
    "    tile = scene.split('_')[1]\n",
    "    date = scene.split('_')[2]\n",
    "    year = date[0:4]\n",
    "    month = date[4:6]\n",
    "    prefix = f'sentinel-s2-l2a-cogs/{tile[0:2]}/{tile[2]}/{tile[3:5]}/{year}/{int(month)}/{scene}'\n",
    "    keys = [ k.split('/')[-1] for k in list(get_matching_s3_keys('sentinel-cogs', prefix=prefix)) ]\n",
    "    \n",
    "    print(json.dumps(keys, indent=4))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Imagery\n",
    "---\n",
    "\n",
    "For this example we will only download a the first matching scene but in a real use-case you would download all of the scenes. We are also just downloading the True Color composite image for this first scene, you can modify this code to download all of the individual band "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2A_34HCH_20171008_0_L2A\n"
     ]
    }
   ],
   "source": [
    "for scene in matching_scenes:\n",
    "    print(scene)\n",
    "    tile = scene.split('_')[1]\n",
    "    date = scene.split('_')[2]\n",
    "    year = date[0:4]\n",
    "    month = date[4:6]\n",
    "    \n",
    "    if not os.path.exists(f'../data/imagery/{scene}'):\n",
    "        os.makedirs(f'../data/imagery/{scene}')\n",
    "    \n",
    "    files = ['TCI.tif']\n",
    "    \n",
    "    for f in files:\n",
    "        key = f'sentinel-s2-l2a-cogs/{tile[0:2]}/{tile[2]}/{tile[3:5]}/{year}/{int(month)}/{scene}/{f}'\n",
    "    \n",
    "        fname = key.split('/')[-1]\n",
    "        s3.download_file('sentinel-cogs', key, f'../data/imagery/{scene}/{fname}')\n",
    "    break # Remove this line to download all of the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
